version: '2'

volumes:
  zookeeper:
  kafka:

services:
  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:3.1.1
    hostname: zookeeper
    networks:
     - dev
    ports:
      - "2181:2181"
    volumes:
      - zookeeper:/var/lib/zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka0:
    container_name: kafka0 
    image: confluentinc/cp-enterprise-kafka:3.1.1
    hostname: kafka0 
    networks:
     - dev
    depends_on:
      - zookeeper
    ports:
      - ':9090:9090'
    volumes:
      - kafka:/var/lib/kafka
    environment:
      KAFKA_BROKER_ID: 0
      KAFKA_BROKER_RACK: 1
      KAFKA_LOG_DIRS: '/var/lib/kafka/kafka0'
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka0:9090'
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka0:9090
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 2
      CONFLUENT_METRICS_REPORTER_PUBLISH_MS: 1000
      KAFKA_DELETE_TOPIC_ENABLE: "true"

  kafka1:
    container_name: kafka1
    image: confluentinc/cp-enterprise-kafka:3.1.1
    hostname: kafka1
    networks:
     - dev
    depends_on:
      - zookeeper
    ports:
      - ':9091:9091'
    volumes:
      - kafka:/var/lib/kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_BROKER_RACK: 1
      KAFKA_LOG_DIRS: '/var/lib/kafka/kafka1'
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka1:9091'
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka0:9090
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 2
      CONFLUENT_METRICS_REPORTER_PUBLISH_MS: 1000
      KAFKA_DELETE_TOPIC_ENABLE: "true"

  kafka2:
    container_name: kafka2
    image: confluentinc/cp-enterprise-kafka:3.1.1
    hostname: kafka2
    networks:
     - dev
    depends_on:
      - zookeeper
    ports:
      - ':9092:9092'
    volumes:
      - kafka:/var/lib/kafka
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_BROKER_RACK: 1
      KAFKA_LOG_DIRS: '/var/lib/kafka/kafka2'
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka2:9092'
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka0:9090
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 2
      CONFLUENT_METRICS_REPORTER_PUBLISH_MS: 1000
      KAFKA_DELETE_TOPIC_ENABLE: "true"

  schema_registry:
    container_name: schema_registry
    image: confluentinc/cp-schema-registry:3.1.1
    hostname: schema_registry
    networks:
     - dev
    depends_on:
      - zookeeper
      - kafka0
      - kafka1
      - kafka2
    ports:
      - ':8081:8081'
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema_registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'

  kafka_rest:
    container_name: kafka_rest
    image: confluentinc/cp-kafka-rest:3.1.1
    hostname: kafka_rest
    networks:
     - dev
    depends_on:
      - zookeeper
      - kafka0
      - kafka1
      - kafka2
      - schema_registry
    ports:
      - "8082:8082"
    environment:
      KAFKA_REST_HOST_NAME: "kafka_rest"
      KAFKA_REST_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: "http://schema_registry:8081"

  connect:
    container_name: connect
    image: confluentinc/cp-kafka-connect:3.1.1
    hostname: connect
    networks:
     - dev
    depends_on:
      - zookeeper
      - kafka0
      - kafka1
      - kafka2
      - schema_registry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'kafka0:9090,kafka1:9091,kafka2:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema_registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema_registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: 'zookeeper:2181'

  control-center:
    container_name: control-center
    image: confluentinc/cp-enterprise-control-center:3.1.1
    hostname: control-center
    networks:
     - dev
    depends_on:
      - zookeeper
      - kafka0
      - kafka1
      - kafka2
      - schema_registry
      - connect
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka0:9090,kafka1:9091,kafka2:9092'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_CONNECT_CLUSTER: 'connect:8083'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      PORT: 9021
      
  elasticsearch:
    container_name: elasticsearch
    image: library/elasticsearch:5.0.2
    restart: always
    hostname: elasticsearch
    networks:
     - dev
    #command: elasticsearch -Des.network.host=0.0.0.0
    depends_on:
      - connect
    ports:
      - "9200:9200"
      - "9300:9300"
      
  kibana:
    container_name: kibana
    image: library/kibana:5.0.2
    restart: always
    hostname: kibana
    networks:
     - dev
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"

  postgres:
    container_name: postgres
    build:
     context: ../../containers/postgres
     args:
      - DDL_URL=${DDL_URL}
    image: hdp/postgres
    networks:
     - dev
    hostname: postgres
    
  ambari-server:
    container_name: ambari-server
    build: 
      context: ../../containers/ambari-server
      args:
       - AMBARI_REPO_URL=${AMBARI_REPO_URL}
    image: hdp/ambari-server
    networks:
     - dev
    hostname: ambari-server
    ports:
     - "8080:8080"
    depends_on:
      - postgres
    expose:
     - "8440"
     - "8441"
    volumes:
     - /shared:/fromlocal
     
  master0:
    container_name: master0
    build:
      context: ../../containers/node
      args:
       - AMBARI_REPO_URL=${AMBARI_REPO_URL}
       - HDP_REPO_URL=${HDP_REPO_URL}
    image: hdp/master
    privileged: true
    networks:
     - dev
    hostname: master0
    depends_on:
      - ambari-server 
    ports:
     # ZooKeeper
     - "2181"
     # HDFS
     - "50070:50070"
     - "8020:8020"
     - "9000:9000"
     - "50090:50090"
     # YARN
     - "8088:8088"
     - "8050:8050"
     - "8025:8025"
     - "8030:8030"
     - "8141:8141"
     - "45454:45454"
     - "10200:10200"
     - "8188:8188"
     - "8190:8190"
     - "19888:19888"
     # HiveServer2
     - "10000:10000"
     - "9999:9999"
     - "9933:9933"
     - "10015:10015"
     - "50111:50111"
     # Storm
     - "8000:8000"
     - "8744:8744"
     # Oozie
     - "11000:11000"
     - "11443:11443"
     # Knox
     - "8443:8443"
     # Ranger
     - "6080:6080"
     - "6182:6182"
     - "6083:6083"
     - "6183:6183"
     # Grafana
     - "3000:3000"
     # Zeppelin
     - "9995:9995"
     # Kerberos
     #- "88:88"
     
  dn0:
    container_name: dn0
    build:
      context: ../../containers/node
      args:
       - AMBARI_REPO_URL=${AMBARI_REPO_URL}
       - HDP_REPO_URL=${HDP_REPO_URL}
    image: hdp/worker
    privileged: true
    networks:
     - dev
    hostname: dn0
    depends_on:
      - ambari-server 
    ports:
     # HDFS
     - "50470"
     - "50075"
     - "50475"
     - "50010"
     - "50020"
     - "50030"
     # HBase
     - "16000"
     - "16010"
     - "16020"
     - "16030"
     # Yarn
     - "45455"
     - "8042"
     # Solr
     - "8983"
     # Sqoop
     - "16000"
     
  dn1:
    container_name: dn1
    build:
      context: ../../containers/node
      args:
       - AMBARI_REPO_URL=${AMBARI_REPO_URL}
       - HDP_REPO_URL=${HDP_REPO_URL}
    image: hdp/worker
    privileged: true
    networks:
     - dev
    hostname: dn1
    depends_on:
      - ambari-server 
    ports:
     # HDFS
     - "50470"
     - "50075"
     - "50475"
     - "50010"
     - "50020"
     - "50030"
     # HBase
     - "16000"
     - "16010"
     - "16020"
     - "16030"
     - "16020"
     - "16030"
     # Yarn
     - "45455"
     - "8042"
     # Solr
     - "8983"
     # Sqoop
     - "16000"
     
  dn2:
    container_name: dn2
    build:
      context: ../../containers/node
      args:
       - AMBARI_REPO_URL=${AMBARI_REPO_URL}
       - HDP_REPO_URL=${HDP_REPO_URL}
    image: hdp/worker
    privileged: true
    networks:
     - dev
    hostname: dn2
    depends_on:
      - ambari-server 
    ports:
     # HDFS
     - "50470"
     - "50075"
     - "50475"
     - "50010"
     - "50020"
     - "50030"
     # HBase
     - "16000"
     - "16010"
     - "16020"
     - "16030"     
     # Yarn
     - "45455"
     - "8042"
     # Solr
     - "8983"
     # Sqoop
     - "16000"

networks:
  dev:
    driver: bridge
